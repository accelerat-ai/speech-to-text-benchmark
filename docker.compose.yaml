version: '3.3'

services:
    mlflow:
        restart: always
        build: .
        image: speechtotextbenchmark:latest
        container_name: mlflow_server
        ports:
            - "5000:5000"
        networks:
            - frontend
            - backend
        volumes:
            - ./data:/data
        command: mlflow ui --backend-store-uri /data/mlflow --default-artifact-root /data/mlflow/artifacts --host 0.0.0.0

    whisper:
        restart: always
        image: onerahmet/openai-whisper-asr-webservice:${IMAGE_BASE}
        container_name: whisper_asr
        ports:
            - "9000:9000"
        networks:
            - frontend
            - backend
        environment:
            - ASR_MODEL=${ASR_MODEL}

    app:
        restart: always
        image: speechtotextbenchmark:latest
        container_name: benchmark
        networks:
            - frontend
            - backend
        volumes:
            - ./data:/data
        environment:
            - MLFLOW_TRACKING_URI=/data/mlflow
        depends_on:
            - mlflow
        command: tail -F anything

networks:
    frontend:
        driver: bridge
    backend:
        driver: bridge

volumes:
    dbdata:
    